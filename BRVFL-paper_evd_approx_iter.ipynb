{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc05559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.io import loadmat\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77fdbbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    std = np.maximum(np.std(x, axis=0), 1/np.sqrt(len(x)))\n",
    "    mean = np.mean(x, axis=0)\n",
    "    return (x - mean) / std\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def one_hot_encoding(label, n_class):\n",
    "    y = np.zeros([len(label), n_class])\n",
    "    for i in range(len(label)):\n",
    "        y[i, label[i]] = 1\n",
    "    return y\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.repeat((np.sum(np.exp(x), axis=1))[:, np.newaxis], len(x[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ab78148",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node = 10\n",
    "n_iter = 1000\n",
    "w_range = [-1, 1] # range of random weights\n",
    "b_range = [0, 1] # range of random biases\n",
    "alpha_1 = 10**(-5) # Gamma distribution parameter\n",
    "alpha_2 = 10**(-5)\n",
    "alpha_3 = 10**(-5)\n",
    "alpha_4 = 10**(-5)\n",
    "tol = 1.0e-3\n",
    "\n",
    "dataset = loadmat('coil20.mat')\n",
    "label = np.array([dataset['Y'][i][0] - 1 for i in range(len(dataset['Y']))])\n",
    "data = dataset['X']\n",
    "n_class = 20\n",
    "\n",
    "# train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.3, random_state=42)\n",
    "# kf = KFold(10, True, 1)\n",
    "val_acc = []\n",
    "max_index = -1\n",
    "\n",
    "X_train = standardize(X_train)\n",
    "n_sample, n_feature = np.shape(X_train)\n",
    "y = one_hot_encoding(y_train, n_class)\n",
    "\n",
    "weights = (w_range[1] - w_range[0]) * np.random.random([n_feature, n_node]) + w_range[0]\n",
    "bias = (b_range[1] - b_range[0]) * np.random.random([1, n_node]) + b_range[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb77e7a6",
   "metadata": {},
   "source": [
    "### 1) Initialization\n",
    "a) Compute $\\mathbf{D}$ where $\\mathbf{D}=\\mathbf{[H,X]}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0e2ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = relu(np.dot(X_train, weights) + np.dot(np.ones([n_sample, 1]), bias))\n",
    "d = np.concatenate([h, X_train], axis=1)\n",
    "# d = np.concatenate([d, np.ones_like(d[:, 0:1])], axis=1) # concat column of 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de2c24",
   "metadata": {},
   "source": [
    "b) Compute $\\mathbf{D}^T\\mathbf{y}, \\mathbf{D}^T\\mathbf{D}$, and its eigenvalues $\\lambda^0_1,\\dots,\\lambda^0_B$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "429b135a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.22371836e-11, -2.28070375e-12, -2.09044845e-12, ...,\n",
       "        2.23715050e+05,  3.83469564e+05,  7.23848649e+05])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dT_y = np.dot(d.T, y)\n",
    "dT_d = np.dot(d.T, d)\n",
    "eigen_val = np.linalg.eigvalsh(dT_d)\n",
    "eigen_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec833d",
   "metadata": {},
   "source": [
    "c) Initialize $\\sigma^2$ and $\\gamma$ to default values <br>\n",
    "Evidence approximation (MAP estimation on the posterior of the hyper-parameters):\n",
    "$$p(\\gamma)=\\text{Gamma}(\\gamma \\mid \\alpha_1, \\alpha_2)$$\n",
    "$$p(\\sigma^2)=\\text{Gamma}(\\sigma^{-2} \\mid \\alpha_3, \\alpha_4)$$\n",
    "$$ \\sigma_*^2, \\gamma_*^2 = \\arg\\max \\left\\{ \\int_{\\mathbf{R}^B} p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{\\beta}, \\sigma^2)p(\\mathbf{\\beta} \\mid \\gamma) p(\\gamma)p(\\sigma^2)\\,d\\beta \\right\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2e6a470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5001' class='' max='5001' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5001/5001 00:41<00:00 logp = 1.1464e+05, ||grad|| = 48,418]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evidence approximation\n",
    "gamma = pm.Model()\n",
    "with gamma:\n",
    "    prec = pm.Gamma('prec', alpha=alpha_1, beta=alpha_2)\n",
    "    var = pm.Gamma('var', alpha=alpha_3, beta=alpha_4)\n",
    "    beta = pm.Normal('beta', mu=0, tau=prec, shape=(n_feature + n_node, n_class))\n",
    "    y_obs = pm.Normal('y_obs', mu=pm.math.dot(d, beta), tau=var, observed=y)\n",
    "    \n",
    "map_estimate =  pm.find_MAP(model=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:  1209.5690847757458\n",
      "var:  18375.41202149414\n",
      "beta:  [[ 1.42841716e-03  3.76067839e-03  3.77665433e-03 ...  1.49610113e-03\n",
      "  -4.94688282e-03 -8.51206940e-05]\n",
      " [-2.24157842e-03  3.22316929e-03  1.31172151e-03 ... -3.11610311e-03\n",
      "  -1.86679358e-03  1.53117666e-03]\n",
      " [-1.96457684e-03 -2.95730023e-03 -3.44664079e-03 ...  1.43150120e-03\n",
      "   1.79082857e-04  1.34722087e-03]\n",
      " ...\n",
      " [ 2.12737483e-02  1.70308621e-02  1.31665476e-02 ...  1.97599765e-02\n",
      "  -4.18342879e-02 -1.17895118e-02]\n",
      " [ 1.28352168e-02  4.08538074e-02  6.00032460e-03 ...  1.21249575e-03\n",
      "  -1.96963041e-02 -7.09148986e-03]\n",
      " [ 1.31309459e-02  3.98866744e-02  9.54498733e-03 ... -3.60943991e-03\n",
      "  -2.55079821e-02 -6.65720825e-03]]\n"
     ]
    }
   ],
   "source": [
    "prec, var, beta = map_estimate['prec'].item(0), map_estimate['var'].item(0), map_estimate['beta']\n",
    "print('prec: ', prec)\n",
    "print('var: ', var)\n",
    "print('beta: ', beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32fcb1",
   "metadata": {},
   "source": [
    "### 2) Posterior update\n",
    "a) Computer posterior mean $\\mathbf{m}$ as in $$\\mathbf{m}=\\frac{1}{\\sigma^2}\\Sigma\\mathbf{D}^T\\mathbf{y}$$ <br>\n",
    "b) Computer posterior covariance $\\Sigma$ as in $$\\Sigma^{-1}=\\gamma\\mathbf{I}+\\frac{1}{\\sigma^2}\\mathbf{D}^T\\mathbf{D}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec75e2",
   "metadata": {},
   "source": [
    "### 3) Hyper-parameters update\n",
    "a) Compute updated eigenvalues $$\\lambda_i=\\frac{1}{\\sigma^2}\\lambda^0_i,\\qquad i=1,\\dots,B$$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf14bb",
   "metadata": {},
   "source": [
    "b) Update $\\gamma$ as in $$\\gamma=\\frac{\\delta + 2\\alpha_1}{\\|\\mathbf{m}\\|^2_2 + 2\\alpha_2}$$\n",
    "c) Update $\\sigma^2$ as in $$\\sigma^2=\\frac{\\|\\mathbf{y}-\\mathbf{D}\\beta\\|^2_2+\\alpha_4}{N-\\delta+2\\alpha_3}$$\n",
    "where $\\delta$ is defined as $$\\delta=\\sum^B_{i=1}\\frac{\\lambda_i}{\\gamma+\\lambda_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after  17  iterations\n",
      "Posterior mean:  [[ 1.69350329e-03  4.46255580e-03  3.49272768e-03 ...  2.11635349e-03\n",
      "  -6.59539646e-03  3.61353008e-04]\n",
      " [-1.70940223e-03  2.46115771e-03  8.43553325e-04 ... -3.99594234e-03\n",
      "  -1.06207711e-03  2.00993749e-03]\n",
      " [ 1.18596342e-03 -6.05819649e-03 -3.10780689e-03 ...  3.12524812e-03\n",
      "   1.55826320e-03  1.42490002e-03]\n",
      " ...\n",
      " [ 5.20126389e-02 -4.23346659e-02  5.55808571e-02 ...  6.79668677e-02\n",
      "  -1.40190191e-01 -3.09014476e-02]\n",
      " [ 9.80171046e-03  4.23311448e-02  1.93670024e-02 ... -3.86976670e-05\n",
      "  -2.73713768e-02 -1.23023494e-02]\n",
      " [ 1.07989846e-02  4.04681096e-02  2.85074590e-02 ... -5.71810845e-03\n",
      "  -4.42219636e-02 -1.18106632e-02]]\n",
      "Posterior covariance:  [[ 6.89936171e-06  1.57516783e-06 -1.48509975e-06 ... -3.46087387e-06\n",
      "  -4.96073629e-06 -3.57272619e-06]\n",
      " [ 1.57516783e-06  1.17384007e-05 -1.29846869e-06 ...  2.46596597e-05\n",
      "   8.62558334e-07 -3.48471184e-06]\n",
      " [-1.48509975e-06 -1.29846869e-06  1.31969763e-05 ...  7.75706910e-06\n",
      "   6.93156220e-06  5.34935725e-06]\n",
      " ...\n",
      " [-3.46087388e-06  2.46596597e-05  7.75706910e-06 ...  3.31884688e-02\n",
      "  -2.22086328e-03 -2.10732011e-03]\n",
      " [-4.96073629e-06  8.62558336e-07  6.93156219e-06 ... -2.22086328e-03\n",
      "   3.53769145e-02 -2.65552066e-03]\n",
      " [-3.57272618e-06 -3.48471184e-06  5.34935725e-06 ... -2.10732011e-03\n",
      "  -2.65552066e-03  3.54659040e-02]]\n",
      "Precision:  26.243745149324532\n",
      "Variance:  0.000540815447409271\n"
     ]
    }
   ],
   "source": [
    "mean_prev = None\n",
    "\n",
    "for iter_ in range(n_iter):\n",
    "    # Posterior update\n",
    "    # update posterior covariance\n",
    "    covar = np.linalg.inv(prec * np.identity(dT_d.shape[1]) + dT_d / var)\n",
    "    # update posterior mean\n",
    "    mean = np.dot(covar, dT_y) / var\n",
    "\n",
    "    # Hyperparameters update\n",
    "    # update eigenvalues\n",
    "    lam = eigen_val / var\n",
    "    # update precision and variance \n",
    "    delta = np.sum(np.divide(lam, lam + prec))\n",
    "    prec = (delta + 2 * alpha_1) / (np.sum(np.square(mean)) + 2 * alpha_2)\n",
    "    var = (np.sum(np.square(y - np.dot(d, beta))) + alpha_4) / (n_sample + delta + 2 * alpha_3)\n",
    "\n",
    "    # Check for convergence\n",
    "    if iter_ != 0 and np.sum(np.abs(mean_prev - mean)) < tol:\n",
    "        print(\"Convergence after \", str(iter_), \" iterations\")\n",
    "        break\n",
    "    mean_prev = np.copy(mean)\n",
    "\n",
    "# Final Posterior update\n",
    "# update posterior covariance\n",
    "covar = np.linalg.inv(prec * np.identity(dT_d.shape[1]) + dT_d / var)\n",
    "# update posterior mean\n",
    "mean = np.dot(covar, dT_y) / var\n",
    "\n",
    "print('Posterior mean: ', mean)\n",
    "print('Posterior covariance: ', covar)\n",
    "print('Precision: ', prec)\n",
    "print('Variance: ', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "X_test = standardize(X_test)\n",
    "n_test_samp = len(X_test)\n",
    "h_test = relu(np.dot(X_test, weights) + np.dot(np.ones([n_test_samp, 1]), bias))\n",
    "d_test = np.concatenate([h_test, X_test], axis=1)\n",
    "result = softmax(np.dot(d_test, beta))\n",
    "result = np.argmax(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = np.sum(np.equal(result, y_test))/len(y_test)\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53e53f2e48b5b02ad96e830940e12ad58baf9aca82a333a77928015526d4f330"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pm3env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
