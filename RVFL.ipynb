{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba92832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.io import loadmat\n",
    "from Laplacian import Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c754d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node = 10 # num of nodes in hidden layer\n",
    "lam_r = 1 # RR regularization parameter\n",
    "lam_l = 1 # MR regularization parameter\n",
    "w_range = [-1, 1] # range of random weights\n",
    "b_range = [0, 1] # range of random biases\n",
    "\n",
    "class RVFL:\n",
    "    \"\"\" RVFL Classifier \"\"\"\n",
    "    \n",
    "    def __init__(self, n_node, C0, lam, w_range, b_range, activation='relu', same_feature=False):\n",
    "        self.n_node = n_node\n",
    "        self.C0 = C0\n",
    "        self.lam = lam\n",
    "        self.w_range = w_range\n",
    "        self.b_range = b_range\n",
    "        self.weight = None\n",
    "        self.bias = None\n",
    "        self.beta = None\n",
    "        a = Activation()\n",
    "        self.activation_function = getattr(a, activation)\n",
    "        self.std = None\n",
    "        self.mean = None\n",
    "        self.same_feature = same_feature\n",
    "        \n",
    "    def train(self, data, label, n_class):\n",
    "        assert len(data.shape) > 1\n",
    "        assert len(data) == len(label)\n",
    "        assert len(label.shape) == 1\n",
    "        \n",
    "        data = self.standardize(data) # Normalize\n",
    "        n_sample = len(data)\n",
    "        n_feature = len(data[0])\n",
    "        self.weight = (self.w_range[1] - self.w_range[0]) * np.random.random([n_feature, self.n_node]) + self.w_range[0]\n",
    "        self.bias = (self.b_range[1] - self.b_range[0]) * np.random.random([1, self.n_node]) + self.b_range[0]\n",
    "        \n",
    "        h = self.activation_function(np.dot(data, self.weight) + np.dot(np.ones([n_sample, 1]), self.bias))\n",
    "        d = np.concatenate([h, data], axis=1)\n",
    "        d = np.concatenate([d, np.ones_like(d[:, 0:1])], axis=1) # concat column of 1s\n",
    "        y = self.one_hot_encoding(label, n_class)\n",
    "        L = np.asarray(Laplacian(data=data, k=3))\n",
    "        # Minimize training complexity\n",
    "        self.beta = self.beta_function(d, L, self.C0, self.lam, y)\n",
    "        print(self.beta)\n",
    "        \n",
    "    def beta_function(self, H, L, C0, lam, y):\n",
    "        # number of samples per class label\n",
    "        n_sample, n_feature = np.shape(H)\n",
    "        C = np.identity(n_sample) * C0\n",
    "\n",
    "        # More labeled examples than hidden neurons\n",
    "        if n_sample > (self.n_node + n_feature):\n",
    "            I = np.identity(n_feature)\n",
    "            inv_arg = I + (H.T @ C @ H) + lam * (H.T @ L @ H)\n",
    "            beta = np.linalg.inv(inv_arg) @ H.T @ C @ y\n",
    "\n",
    "        # Less labeled examples than hidden neurons (apparently the more common case)\n",
    "        else:\n",
    "            I = np.identity(n_sample)\n",
    "            inv_arg = I + (C @ H @ H.T) + lam * (L @ H @ H.T)\n",
    "            beta = (H.T @ np.linalg.inv(inv_arg) @ C @ y)\n",
    "            \n",
    "        return beta\n",
    "\n",
    "    def predict(self, data, raw_output=False):\n",
    "        data = self.standardize(data) # Normalize\n",
    "        h = self.activation_function(np.dot(data, self.weight) + self.bias)\n",
    "        d = np.concatenate([h, data], axis=1)\n",
    "        d = np.concatenate([d, np.ones_like(d[:, 0:1])], axis=1)\n",
    "        result = self.softmax(np.dot(d, self.beta))\n",
    "        if not raw_output:\n",
    "            result = np.argmax(result, axis=1)\n",
    "        return result\n",
    "    \n",
    "    def eval(self, data, label):\n",
    "        assert len(data.shape) > 1\n",
    "        assert len(data) == len(label)\n",
    "        assert len(label.shape) == 1\n",
    "        \n",
    "        result = self.predict(data, False)\n",
    "        acc = np.sum(np.equal(result, label))/len(label)\n",
    "        return acc\n",
    "        \n",
    "    def one_hot_encoding(self, label, n_class):\n",
    "        y = np.zeros([len(label), n_class])\n",
    "        for i in range(len(label)):\n",
    "            y[i, label[i]] = 1\n",
    "        return y\n",
    "    \n",
    "    def standardize(self, x):\n",
    "        if self.same_feature is True:\n",
    "            if self.std is None:\n",
    "                self.std = np.maximum(np.std(x), 1/np.sqrt(len(x)))\n",
    "            if self.mean is None:\n",
    "                self.mean = np.mean(x)\n",
    "            return (x - self.mean) / self.std\n",
    "        else:\n",
    "            if self.std is None:\n",
    "                self.std = np.maximum(np.std(x, axis=0), 1/np.sqrt(len(x)))\n",
    "            if self.mean is None:\n",
    "                self.mean = np.mean(x, axis=0)\n",
    "            return (x - self.mean) / self.std\n",
    "        \n",
    "    def softmax(self, x):\n",
    "        return np.exp(x) / np.repeat((np.sum(np.exp(x), axis=1))[:, np.newaxis], len(x[0]), axis=1)\n",
    "        \n",
    "class Activation:\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.e ** (-x))\n",
    "    \n",
    "    def sine(self, x):\n",
    "        return np.sin(x)\n",
    "    \n",
    "    def sign(self, x):\n",
    "        return np.sign(x)\n",
    "    \n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b2d36f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 1\n",
      "[[ 5.04374511e-04  2.13875229e-03 -1.17450988e-03 ... -3.45333677e-03\n",
      "  -6.01979965e-03  5.38097509e-04]\n",
      " [ 3.30773902e-03 -3.65858141e-05  1.08044377e-03 ... -4.21977981e-03\n",
      "   4.92154674e-03  1.13758241e-03]\n",
      " [ 7.72101021e-04 -1.81352010e-03  2.05893643e-03 ...  5.73386555e-03\n",
      "  -5.50368099e-03 -6.33692566e-04]\n",
      " ...\n",
      " [ 2.31899840e-02  3.30697065e-02  3.12812553e-03 ...  1.21468185e-03\n",
      "  -7.00948511e-03 -2.54379322e-03]\n",
      " [ 2.20132182e-02  3.41635118e-02  3.01462741e-03 ...  7.95530117e-05\n",
      "  -6.24607254e-03 -2.19576766e-03]\n",
      " [ 2.27261934e-02  1.08032377e-02 -1.23046309e-03 ...  4.54572170e-02\n",
      "   4.71208353e-02  3.07393173e-02]]\n",
      "Validation accuracy: 0.9310344827586207\n",
      "Validation: 2\n",
      "[[ 0.0017806   0.00181141  0.00190106 ... -0.00593323  0.00098155\n",
      "   0.00136527]\n",
      " [ 0.00343268 -0.00120063  0.0018041  ... -0.00026207  0.00017826\n",
      "   0.00028931]\n",
      " [-0.00021828  0.00025807 -0.0003833  ... -0.00393594  0.00258719\n",
      "   0.00100095]\n",
      " ...\n",
      " [ 0.01959066  0.0274224  -0.00335025 ...  0.00546946  0.00390542\n",
      "  -0.00407489]\n",
      " [ 0.01970812  0.02825088 -0.00145436 ...  0.002331    0.00252638\n",
      "  -0.00386981]\n",
      " [-0.00100841  0.02703493 -0.01063846 ...  0.08502038 -0.00772588\n",
      "   0.0325875 ]]\n",
      "Validation accuracy: 0.9137931034482759\n",
      "Validation: 3\n",
      "[[-1.91325319e-04  1.43181142e-03  5.60614899e-03 ...  2.79499983e-03\n",
      "  -8.82721857e-04 -3.77252618e-04]\n",
      " [ 6.06012698e-04 -3.35786156e-04  3.20786797e-03 ... -2.89529275e-03\n",
      "  -8.46829936e-03 -4.66952222e-04]\n",
      " [-9.61518601e-06 -9.72376401e-04  1.20709095e-03 ... -5.49923134e-04\n",
      "   9.32134964e-04  5.06605951e-04]\n",
      " ...\n",
      " [ 1.84423594e-02  3.43135315e-02 -9.58833781e-03 ... -3.88774054e-03\n",
      "   8.44082612e-03 -2.71543937e-03]\n",
      " [ 1.80634794e-02  3.50975343e-02 -7.67478254e-03 ... -6.59622539e-03\n",
      "   5.03938906e-03 -2.43754443e-03]\n",
      " [ 6.39840510e-02 -4.01959953e-03 -6.01794364e-03 ...  4.44988949e-02\n",
      "   2.00493012e-03  2.31344523e-02]]\n",
      "Validation accuracy: 0.9217391304347826\n",
      "Validation: 4\n",
      "[[-1.21459689e-03  2.07865633e-03 -2.09556037e-03 ...  2.11922829e-03\n",
      "  -1.57384595e-03 -7.11367556e-05]\n",
      " [ 1.38418070e-03 -5.93807821e-06 -1.16599660e-03 ... -3.64449219e-04\n",
      "   6.36202511e-03  7.46781469e-04]\n",
      " [ 1.07420191e-03  3.02604899e-04 -2.70216706e-04 ...  8.61215189e-04\n",
      "   4.12311912e-03  2.08665830e-05]\n",
      " ...\n",
      " [ 1.42159634e-02  3.48114405e-02 -1.33747011e-04 ...  1.68647584e-03\n",
      "   2.22654655e-03 -1.80588409e-03]\n",
      " [ 1.41225839e-02  3.56141999e-02  2.00889659e-03 ... -9.89703126e-04\n",
      "  -1.11565584e-03 -1.70489405e-03]\n",
      " [ 5.57399701e-02 -2.52671260e-02  7.45938766e-02 ...  5.60396364e-02\n",
      "   1.08960226e-01  4.62917477e-03]]\n",
      "Validation accuracy: 0.9478260869565217\n",
      "Validation: 5\n",
      "[[-1.01445342e-03  7.38712950e-04 -6.78052664e-03 ... -1.30309984e-03\n",
      "   5.56122572e-03  1.31504280e-03]\n",
      " [-7.98226542e-04  2.48661106e-04 -2.96979002e-03 ... -8.16942556e-04\n",
      "  -1.09567410e-03  6.84968225e-04]\n",
      " [ 5.21107381e-06  8.41314217e-04  1.71211718e-03 ... -2.51737251e-03\n",
      "  -3.77539554e-03  5.07817097e-04]\n",
      " ...\n",
      " [ 1.82207234e-02  2.98377276e-02  4.11430786e-03 ...  4.36068556e-03\n",
      "  -1.07535016e-02 -2.04217306e-03]\n",
      " [ 1.81996142e-02  3.03356617e-02  5.01026035e-03 ...  1.31965591e-03\n",
      "  -1.27700933e-02 -1.91301565e-03]\n",
      " [ 3.02758252e-02  1.11956862e-02  8.08978778e-02 ...  1.04238937e-01\n",
      "   1.65904829e-02  2.48581628e-02]]\n",
      "Validation accuracy: 0.9130434782608695\n",
      "Validation: 6\n",
      "[[-6.88745804e-04  8.85305064e-04  2.57163794e-03 ...  5.35291353e-04\n",
      "  -6.34177970e-03 -5.47310014e-04]\n",
      " [-1.16138814e-03 -2.96673701e-04 -9.53892297e-04 ... -2.21010014e-03\n",
      "  -1.14843372e-03  7.54761822e-04]\n",
      " [ 5.22046011e-06 -5.01180592e-04  3.56892873e-03 ... -1.27277305e-03\n",
      "  -3.61595783e-03  4.25461462e-04]\n",
      " ...\n",
      " [ 1.03822921e-02  3.08980176e-02  5.43149832e-04 ...  1.28278520e-03\n",
      "  -1.95245449e-03 -1.29031609e-03]\n",
      " [ 1.08230923e-02  3.11986926e-02  2.00180153e-03 ... -1.85610525e-03\n",
      "  -5.45336720e-03 -1.32951588e-03]\n",
      " [ 4.72577072e-02 -4.16379529e-02 -1.52565272e-02 ...  1.28524047e-01\n",
      "   2.20950095e-01  3.29658037e-03]]\n",
      "Validation accuracy: 0.9043478260869565\n",
      "Validation: 7\n",
      "[[-0.00068708  0.00064783  0.00104963 ... -0.00270328  0.00285768\n",
      "  -0.00034709]\n",
      " [-0.00061578  0.00171784 -0.00160868 ... -0.00113217 -0.00108831\n",
      "  -0.00035143]\n",
      " [-0.00348522  0.00197194 -0.00111973 ... -0.00430517 -0.00266629\n",
      "   0.00114727]\n",
      " ...\n",
      " [ 0.01621576  0.03350418  0.00042129 ...  0.00483596 -0.00193978\n",
      "  -0.00208661]\n",
      " [ 0.01610964  0.03421744  0.00189336 ...  0.00212081 -0.00385916\n",
      "  -0.00172257]\n",
      " [ 0.04261288 -0.02027564 -0.00416285 ...  0.16760799  0.1012671\n",
      "   0.01591657]]\n",
      "Validation accuracy: 0.9478260869565217\n",
      "Validation: 8\n",
      "[[ 1.89019259e-03  2.74692873e-04  7.19154876e-04 ... -6.18498313e-05\n",
      "   7.02554156e-03 -2.93865944e-04]\n",
      " [ 1.97303875e-03 -3.30405375e-04 -3.82262845e-03 ...  2.10611865e-03\n",
      "  -2.06781574e-03  3.13229467e-04]\n",
      " [-1.90167101e-03  2.91481634e-03  2.69053282e-04 ... -6.36651205e-04\n",
      "   2.28578810e-03  1.40530722e-04]\n",
      " ...\n",
      " [ 1.79769650e-02  3.00914740e-02  6.21333532e-03 ...  1.71303518e-03\n",
      "  -7.88286409e-03 -2.26415613e-03]\n",
      " [ 1.83752442e-02  3.09399610e-02  7.13709576e-03 ... -1.60251815e-03\n",
      "  -1.00706662e-02 -1.97418562e-03]\n",
      " [ 4.65090934e-02 -1.54841910e-02  1.09470822e-01 ...  3.49749139e-03\n",
      "  -7.43297939e-02  2.30347736e-02]]\n",
      "Validation accuracy: 0.9304347826086956\n",
      "Validation: 9\n",
      "[[-1.00086652e-03  2.42660525e-03 -4.42568097e-03 ...  2.84011555e-03\n",
      "   7.50078643e-03  4.77292981e-04]\n",
      " [-5.21704249e-04 -1.31135775e-03  2.39192834e-05 ... -1.11455534e-03\n",
      "  -2.08152904e-03  6.76842944e-05]\n",
      " [-5.82448377e-04  4.20542272e-04  5.50689097e-05 ... -1.99792377e-03\n",
      "  -9.50326485e-03  1.46901052e-04]\n",
      " ...\n",
      " [ 1.52527079e-02  3.13045407e-02 -4.05223383e-03 ... -5.51695636e-03\n",
      "  -4.89336654e-03 -1.67362236e-03]\n",
      " [ 1.53016506e-02  3.23006965e-02 -8.24282519e-04 ... -8.09516707e-03\n",
      "  -8.30471748e-03 -1.73113067e-03]\n",
      " [ 3.07979457e-02 -1.03624307e-02  5.96538861e-02 ...  8.95006938e-02\n",
      "   3.37607587e-02  3.69521054e-02]]\n",
      "Validation accuracy: 0.9478260869565217\n",
      "Validation: 10\n",
      "[[ 3.41525485e-03 -3.04011948e-03  7.29282295e-04 ...  2.46712195e-04\n",
      "   5.17405341e-04  1.32743903e-03]\n",
      " [ 4.05582283e-04  1.61344804e-04  4.69719125e-04 ...  1.88743315e-03\n",
      "   1.44927531e-03 -3.03686235e-04]\n",
      " [ 1.67157148e-03  1.00557325e-03 -3.62060821e-03 ... -4.60606525e-05\n",
      "   4.37677157e-03  5.49324216e-05]\n",
      " ...\n",
      " [ 1.72394778e-02  3.10242339e-02  4.84949373e-04 ...  1.37949256e-03\n",
      "  -3.97907480e-04 -3.19271045e-03]\n",
      " [ 1.75242918e-02  3.04714751e-02  2.04324152e-03 ... -2.87683710e-04\n",
      "  -3.34106312e-03 -3.09672391e-03]\n",
      " [-1.62112366e-02  6.69248174e-03  3.08523220e-02 ...  2.31169951e-02\n",
      "   4.80469231e-02  2.44493908e-02]]\n",
      "Validation accuracy: 0.9217391304347826\n",
      "[[-0.00146842  0.00463979 -0.00181849 ...  0.00092607  0.00533721\n",
      "   0.00146742]\n",
      " [-0.00029033  0.00097508 -0.00324825 ...  0.00148484  0.00021838\n",
      "   0.00107006]\n",
      " [ 0.00229311  0.00035421  0.00267735 ...  0.0033767   0.0002041\n",
      "   0.00019819]\n",
      " ...\n",
      " [ 0.01926619  0.02821619 -0.00024111 ... -0.00200067 -0.00546675\n",
      "  -0.00178168]\n",
      " [ 0.01885274  0.02953436  0.00249716 ... -0.00470585 -0.00869043\n",
      "  -0.00168261]\n",
      " [ 0.02545181 -0.02805977  0.03839741 ...  0.08379448  0.0961071\n",
      "   0.01305861]]\n",
      "\n",
      "Test accuracy: 0.8923611111111112\n"
     ]
    }
   ],
   "source": [
    "# coil20 dataset\n",
    "if __name__==\"__main__\":\n",
    "    dataset = loadmat('coil20.mat')\n",
    "    label = np.array([dataset['Y'][i][0] - 1 for i in range(len(dataset['Y']))])\n",
    "    data = dataset['X']\n",
    "    n_class = len(np.unique(label))\n",
    "\n",
    "    # train-test-split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    val_acc = []\n",
    "    max_index = -1\n",
    "    \n",
    "    for i, kf_values in enumerate(kf.split(X_train, y_train)):\n",
    "    #     print(f'train: {train_index}, val: {val_index}')\n",
    "        print('Validation: {}'.format(i + 1))\n",
    "        train_index, val_index = kf_values\n",
    "        X_val_train, X_val_test = X_train[train_index], X_train[val_index]\n",
    "        y_val_train, y_val_test = y_train[train_index], y_train[val_index]\n",
    "        model = RVFL(n_node, lam_r, lam_l,  w_range, b_range)\n",
    "        model.train(X_val_train, y_val_train, n_class)\n",
    "        prediction = model.predict(X_val_test, True)\n",
    "        acc = model.eval(X_val_test, y_val_test)\n",
    "        print(f'Validation accuracy: {acc}')\n",
    "        val_acc.append(acc)\n",
    "        if acc >= max(val_acc):\n",
    "            max_index = train_index\n",
    "\n",
    "    X_train, y_train = X_train[max_index], y_train[max_index]\n",
    "    model = RVFL(n_node, lam_r, lam_l, w_range, b_range)\n",
    "    model.train(X_train, y_train, n_class)\n",
    "    prediction = model.predict(X_test, True)\n",
    "    acc = model.eval(X_test, y_test)\n",
    "    print(f'\\nTest accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c8204b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 1\n",
      "Validation accuracy: 0.4318181818181818\n",
      "Validation: 2\n",
      "Validation accuracy: 0.4772727272727273\n",
      "Validation: 3\n",
      "Validation accuracy: 0.5454545454545454\n",
      "Validation: 4\n",
      "Validation accuracy: 0.5\n",
      "Validation: 5\n",
      "Validation accuracy: 0.29545454545454547\n",
      "Validation: 6\n",
      "Validation accuracy: 0.5909090909090909\n",
      "Validation: 7\n",
      "Validation accuracy: 0.4318181818181818\n",
      "Validation: 8\n",
      "Validation accuracy: 0.5227272727272727\n",
      "Validation: 9\n",
      "Validation accuracy: 0.5454545454545454\n",
      "Validation: 10\n",
      "Validation accuracy: 0.5681818181818182\n",
      "Accuracy: 0.5363636363636364\n"
     ]
    }
   ],
   "source": [
    "# g50c dataset\n",
    "if __name__==\"__main__\":\n",
    "    dataset = loadmat('g50c.mat')\n",
    "    label = np.array([dataset['y'][i][0] for i in range(len(dataset['y']))])\n",
    "    data = dataset['X']\n",
    "    n_class = len(np.unique(label))\n",
    "\n",
    "    # train-test-split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    val_acc = []\n",
    "    max_index = -1\n",
    "    \n",
    "    for i, kf_values in enumerate(kf.split(X_train, y_train)):\n",
    "    #     print(f'train: {train_index}, val: {val_index}')\n",
    "        print('Validation: {}'.format(i + 1))\n",
    "        train_index, val_index = kf_values\n",
    "        X_val_train, X_val_test = X_train[train_index], X_train[val_index]\n",
    "        y_val_train, y_val_test = y_train[train_index], y_train[val_index]\n",
    "        model = RVFL(n_node, lam, w_range, b_range)\n",
    "        model.train(X_val_train, y_val_train, n_class)\n",
    "        prediction = model.predict(X_val_test, True)\n",
    "        acc = model.eval(X_val_test, y_val_test)\n",
    "        print(f'Validation accuracy: {acc}')\n",
    "        val_acc.append(acc)\n",
    "        if acc >= max(val_acc):\n",
    "            max_index = train_index\n",
    "\n",
    "    X_train, y_train = X_train[max_index], y_train[max_index]\n",
    "    model = RVFL(n_node, lam, w_range, b_range)\n",
    "    model.train(X_train, y_train, n_class)\n",
    "    prediction = model.predict(X_test, True)\n",
    "    acc = model.eval(X_test, y_test)\n",
    "    print(f'\\nTest accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9417004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 1\n",
      "Validation accuracy: 0.8633540372670807\n",
      "Validation: 2\n",
      "Validation accuracy: 0.8509316770186336\n",
      "Validation: 3\n",
      "Validation accuracy: 0.8757763975155279\n",
      "Validation: 4\n",
      "Validation accuracy: 0.8944099378881988\n",
      "Validation: 5\n",
      "Validation accuracy: 0.9130434782608695\n",
      "Validation: 6\n",
      "Validation accuracy: 0.90625\n",
      "Validation: 7\n",
      "Validation accuracy: 0.81875\n",
      "Validation: 8\n",
      "Validation accuracy: 0.89375\n",
      "Validation: 9\n",
      "Validation accuracy: 0.91875\n",
      "Validation: 10\n",
      "Validation accuracy: 0.9125\n",
      "Accuracy: 0.8955223880597015\n"
     ]
    }
   ],
   "source": [
    "# uspst dataset\n",
    "if __name__==\"__main__\":\n",
    "    dataset = loadmat('uspst.mat')\n",
    "    label = np.array([dataset['y'][i][0] for i in range(len(dataset['y']))])\n",
    "    data = dataset['X']\n",
    "    n_class = len(np.unique(label))\n",
    "\n",
    "    # train-test-split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    val_acc = []\n",
    "    max_index = -1\n",
    "    \n",
    "    for i, kf_values in enumerate(kf.split(X_train, y_train)):\n",
    "    #     print(f'train: {train_index}, val: {val_index}')\n",
    "        print('Validation: {}'.format(i + 1))\n",
    "        train_index, val_index = kf_values\n",
    "        X_val_train, X_val_test = X_train[train_index], X_train[val_index]\n",
    "        y_val_train, y_val_test = y_train[train_index], y_train[val_index]\n",
    "        model = RVFL(n_node, lam, w_range, b_range)\n",
    "        model.train(X_val_train, y_val_train, n_class)\n",
    "        prediction = model.predict(X_val_test, True)\n",
    "        acc = model.eval(X_val_test, y_val_test)\n",
    "        print(f'Validation accuracy: {acc}')\n",
    "        val_acc.append(acc)\n",
    "        if acc >= max(val_acc):\n",
    "            max_index = train_index\n",
    "\n",
    "    X_train, y_train = X_train[max_index], y_train[max_index]\n",
    "    model = RVFL(n_node, lam, w_range, b_range)\n",
    "    model.train(X_train, y_train, n_class)\n",
    "    prediction = model.predict(X_test, True)\n",
    "    acc = model.eval(X_test, y_test)\n",
    "    print(f'\\nTest accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659df8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d29531488e2b7bac10af08b59c5a0d1dca9077738f8661c2e75b8529990c25ab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
